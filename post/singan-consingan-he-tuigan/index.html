<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>SinGAN  ConSinGAN 和 TuiGAN | yczzc</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://yczzc.github.io/favicon.ico?v=1587138707097">
<link rel="stylesheet" href="https://yczzc.github.io/styles/main.css">



<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="SinGAN
Technion和Google提出的&quot;SinGAN: Learning a Generative Model from a Single Natural Image&quot;（2019 ICCV的最佳论文）论文链接..." />
    <meta name="keywords" content="" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://yczzc.github.io">
        <img src="https://yczzc.github.io/images/avatar.png?v=1587138707097" class="site-logo">
        <h1 class="site-title">yczzc</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            首页
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://yczzc.github.io/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">SinGAN  ConSinGAN 和 TuiGAN</h2>
            <div class="post-date">2020-04-16</div>
            
            <div class="post-content" v-pre>
              <p><strong>SinGAN</strong><br>
Technion和Google提出的&quot;SinGAN: Learning a Generative Model from a Single Natural Image&quot;（2019 ICCV的最佳论文）<a href="https://arxiv.org/pdf/1905.01164.pdf">论文链接</a>  <a href="https://www.youtube.com/watch?v=mdAcPe74tZI&amp;feature=youtu.be&amp;t=3217">视频链接</a>，是第一个拿单张图像进行训练的非条件生成网络。<br>
效果如下：（最左侧一列是训练图像，右侧几列是生成图像）<br>
<img src="https://yczzc.github.io/post-images/1587030102750.png" alt="" loading="lazy"><br>
SinGAN为多个GAN组成的金字塔结构。每一层的GAN是为了学到图像中的某一个patch，低层的GAN处理低分辨率的图像patch，patch size比较大，能快速理解图像；随着层数的增加，GAN处理更高分辨率的图像，patch size逐渐变小，逐渐学到图像的细节。这就是论文中提到的coarse-to-fine。<br>
此外，每一层的判别器并不将图像看作整体，通过这种方法， 它就可以知道真实的patch是什么样子。这样，生成器就可以通过生成在全局来看不同，但仅从patch来看却相似的图像，来达到“欺诈”的目的。<br>
对于第一个生成器，它的输入仅有随机噪声z。对于在更高分辨率上工作的生成器，它是将前一个生成器生成的图像作为输入，在此基础上生成比当前还要高分辨率的图像。所有的生成器都是单独训练的，也就是说在训练当前生成器时，所有以前的生成器的权重都保持不变。</p>
<figure data-type="image" tabindex="1"><img src="https://yczzc.github.io/post-images/1587030892081.png" alt="" loading="lazy"></figure>
<p><strong>ConSinGAN</strong><br>
Adobe和汉堡大学的研究人员发现，在某段时间内仅训练一个生成器会限制生成器之间的交互作用。因此，他们提出了同时训练多个生成器的ConSinGAN<a href="https://arxiv.org/pdf/2003.11512.pdf">论文链接</a>。效果图：<br>
<img src="https://yczzc.github.io/post-images/1587032979129.png" alt="" loading="lazy"><br>
为了防止过拟合，在某一个Stage时，模型只训练一部分生成器，而不是所有的生成器。此外，对于不同的生成器采用了不同的学习率。默认情况下，最多同时训练3个生成器，并对较低的生成器，分别将学习率调至0.1和0.001。<br>
<img src="https://yczzc.github.io/post-images/1587032532572.png" alt="" loading="lazy"></p>
<p><strong>TuiGAN</strong><br>
TuiGAN<a href="https://arxiv.xilesou.top/pdf/2004.04634.pdf">论文链接</a>研究的问题是图像转换，作者认为即便源域和目标域图像仅各有一幅图像也能完成转换任务。效果图：<br>
<img src="https://yczzc.github.io/post-images/1587034482162.png" alt="" loading="lazy"><br>
和之间两种模型类似，由多GAN组成的结构能学到有低分辨率图像到高分辨率图像的“渐进式转变”。最开始的GAN处理低分辨率图像，之后的生成器接收当前输入的本层图像和上一个小尺度生成器所生成图像的上采样的融合。<br>
<img src="https://yczzc.github.io/post-images/1587034342026.png" alt="" loading="lazy"><br>
在生成器中，利用一个attention注意力模块整合当前的本层图像和上一个小尺度生成器所生成的图像，完成不同尺度图像的融合。<br>
<img src="https://yczzc.github.io/post-images/1587034395040.png" alt="" loading="lazy"></p>
<p>参考：</p>
<ol>
<li>https://arxiv.org/pdf/1905.01164.pdf</li>
<li>https://arxiv.org/pdf/2003.11512.pdf</li>
<li>https://arxiv.xilesou.top/pdf/2004.04634.pdf</li>
<li>https://zhuanlan.zhihu.com/p/120846837</li>
<li>https://zhuanlan.zhihu.com/p/129045166</li>
</ol>

            </div>
            
            

            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>






  </body>
</html>
